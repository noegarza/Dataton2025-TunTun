{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el archivo CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/DATATHON/Venta.csv')\n",
        "\n",
        "# Verificar que las columnas esperadas existan\n",
        "expected_columns = ['TIENDA_ID', 'MES_ID', 'VENTA_TOTAL']\n",
        "if not all(col in df.columns for col in expected_columns):\n",
        "    print(\"Error: El archivo CSV debe contener las columnas 'TIENDA_ID', 'MES_ID' y 'VENTA_TOTAL'\")\n",
        "else:\n",
        "    # Calcular promedio de VENTA_TOTAL por tienda, usando todos sus registros actuales\n",
        "    resumen = df.groupby('TIENDA_ID')['VENTA_TOTAL'].mean().reset_index()\n",
        "    resumen.columns = ['TIENDA_ID', 'PROMEDIO_VENTA_TOTAL']\n",
        "\n",
        "    # Guardar el resumen en un archivo CSV\n",
        "    output_path = '/content/drive/MyDrive/DATATHON/Promedio_Venta.csv'\n",
        "    resumen.to_csv(output_path, index=False)\n",
        "    print(f\"\\nArchivo exportado exitosamente a: {output_path}\")\n",
        "\n",
        "    # Imprimir el resumen\n",
        "    print(\"\\nResumen de tiendas con su promedio de venta:\")\n",
        "    print(resumen)\n",
        "\n",
        "# Cargar los archivos\n",
        "promedio_venta_path = '/content/drive/MyDrive/DATATHON/Promedio_Venta.csv'\n",
        "dim_tienda_path = '/content/drive/MyDrive/DATATHON/DIM_TIENDA_TEST.csv'\n",
        "\n",
        "promedio_df = pd.read_csv(promedio_venta_path)\n",
        "dim_tienda_df = pd.read_csv(dim_tienda_path)\n",
        "\n",
        "# Verificar que la columna TIENDA_ID exista en ambos DataFrames\n",
        "if 'TIENDA_ID' not in promedio_df.columns or 'TIENDA_ID' not in dim_tienda_df.columns:\n",
        "    print(\"Error: Ambos archivos deben contener la columna 'TIENDA_ID'\")\n",
        "else:\n",
        "    # Realizar el merge\n",
        "    merged_df = dim_tienda_df.merge(promedio_df, on='TIENDA_ID', how='left')\n",
        "\n",
        "    # Guardar el archivo combinado\n",
        "    output_path = '/content/drive/MyDrive/DATATHON/DIM_TIENDA_TEST_Con_Promedio.csv'\n",
        "    merged_df.to_csv(output_path, index=False)\n",
        "    print(f\"\\nArchivo combinado exportado exitosamente a: {output_path}\")\n",
        "\n",
        "    # Mostrar los primeros registros del archivo combinado\n",
        "    print(\"\\nPrimeros registros del archivo combinado:\")\n",
        "    print(merged_df.head())\n",
        "\n",
        "dim_tienda_path = '/content/drive/MyDrive/DATATHON/DIM_TIENDA.csv'\n",
        "dim_tienda_train_df = pd.read_csv(dim_tienda_path)\n",
        "\n",
        "# Verificar que la columna TIENDA_ID exista en ambos DataFrames\n",
        "if 'TIENDA_ID' not in promedio_df.columns or 'TIENDA_ID' not in dim_tienda_train_df.columns:\n",
        "    print(\"Error: Ambos archivos deben contener la columna 'TIENDA_ID'\")\n",
        "else:\n",
        "    # Realizar el merge\n",
        "    merged_df_train = dim_tienda_train_df.merge(promedio_df, on='TIENDA_ID', how='left')\n",
        "\n",
        "    # Guardar el archivo combinado\n",
        "    output_path = '/content/drive/MyDrive/DATATHON/DIM_TIENDA_TRAIN_Con_Promedio.csv'\n",
        "    merged_df_train.to_csv(output_path, index=False)\n",
        "    print(f\"\\nArchivo combinado exportado exitosamente a: {output_path}\")\n",
        "\n",
        "    # Mostrar los primeros registros del archivo combinado\n",
        "    print(\"\\nPrimeros registros del archivo combinado:\")\n",
        "    print(merged_df_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zub8KhePPkdZ",
        "outputId": "abc256f8-ce2f-4046-8a4f-a9adbf586d2e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Archivo exportado exitosamente a: /content/drive/MyDrive/DATATHON/Promedio_Venta.csv\n",
            "\n",
            "Resumen de tiendas con su promedio de venta:\n",
            "      TIENDA_ID  PROMEDIO_VENTA_TOTAL\n",
            "0             1          7.080276e+05\n",
            "1             2          8.994741e+05\n",
            "2             3          8.274871e+05\n",
            "3             4          1.247370e+06\n",
            "4             5          1.596267e+06\n",
            "...         ...                   ...\n",
            "1048       1052          1.136733e+06\n",
            "1049       1053          7.660571e+05\n",
            "1050       1054          1.561485e+06\n",
            "1051       1055          1.014392e+06\n",
            "1052       1056          1.284810e+06\n",
            "\n",
            "[1053 rows x 2 columns]\n",
            "\n",
            "Archivo combinado exportado exitosamente a: /content/drive/MyDrive/DATATHON/DIM_TIENDA_TEST_Con_Promedio.csv\n",
            "\n",
            "Primeros registros del archivo combinado:\n",
            "   TIENDA_ID  PLAZA_CVE NIVELSOCIOECONOMICO_DES ENTORNO_DES  MTS2VENTAS_NUM  \\\n",
            "0        680          1                       C       Hogar          102.36   \n",
            "1        730          1                       C       Hogar           97.43   \n",
            "2        650          1                       C       Hogar          117.01   \n",
            "3        670          1                       C        Base          109.76   \n",
            "4        800          1                       C    Peatonal            0.00   \n",
            "\n",
            "   PUERTASREFRIG_NUM  CAJONESESTACIONAMIENTO_NUM  LATITUD_NUM  LONGITUD_NUM  \\\n",
            "0                 13                           0     25.65488    -100.21207   \n",
            "1                 14                           0     25.66315    -100.22738   \n",
            "2                 13                           0     25.66404    -100.22993   \n",
            "3                 13                           0     25.66508    -100.26338   \n",
            "4                  0                           0     25.69367    -100.21433   \n",
            "\n",
            "  SEGMENTO_MAESTRO_DESC LID_UBICACION_TIENDA DATASET  PROMEDIO_VENTA_TOTAL  \n",
            "0         Hogar Reunión          UT_DENSIDAD    TEST          6.503506e+05  \n",
            "1         Hogar Reunión          UT_DENSIDAD    TEST          1.324069e+06  \n",
            "2         Hogar Reunión          UT_DENSIDAD    TEST          9.372804e+05  \n",
            "3         Hogar Reunión          UT_DENSIDAD    TEST          7.728227e+05  \n",
            "4        Parada Técnica  UT_TRAFICO_PEATONAL    TEST          5.228823e+05  \n",
            "\n",
            "Archivo combinado exportado exitosamente a: /content/drive/MyDrive/DATATHON/DIM_TIENDA_TRAIN_Con_Promedio.csv\n",
            "\n",
            "Primeros registros del archivo combinado:\n",
            "   TIENDA_ID  PLAZA_CVE NIVELSOCIOECONOMICO_DES ENTORNO_DES  MTS2VENTAS_NUM  \\\n",
            "0        126          1                      BC       Hogar          127.42   \n",
            "1        681          1                       C       Hogar          128.13   \n",
            "2        117          1                       C        Base           87.62   \n",
            "3        682          1                       C       Hogar           90.70   \n",
            "4        275          1                       C       Hogar           95.30   \n",
            "\n",
            "   PUERTASREFRIG_NUM  CAJONESESTACIONAMIENTO_NUM  LATITUD_NUM  LONGITUD_NUM  \\\n",
            "0                 13                           7     25.69107    -100.21261   \n",
            "1                 13                           0     25.73571    -100.18086   \n",
            "2                 11                          11     25.71883    -100.19133   \n",
            "3                 13                           0     25.66952    -100.20744   \n",
            "4                 13                           6     25.73766    -100.16116   \n",
            "\n",
            "  SEGMENTO_MAESTRO_DESC LID_UBICACION_TIENDA DATASET  PROMEDIO_VENTA_TOTAL  \n",
            "0         Hogar Reunión          UT_DENSIDAD   TRAIN         897943.461429  \n",
            "1         Hogar Reunión          UT_DENSIDAD   TRAIN         875823.110000  \n",
            "2         Hogar Reunión          UT_DENSIDAD   TRAIN         454438.265714  \n",
            "3         Hogar Reunión          UT_DENSIDAD   TRAIN         945847.573810  \n",
            "4         Hogar Reunión          UT_DENSIDAD   TRAIN         859411.378095  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carga de archivo con el promedio de ventas por tienda**"
      ],
      "metadata": {
        "id": "h6aOtx5v5ure"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0ahku_8yW6f",
        "outputId": "10b7152e-af96-4cbd-f07d-c8ffa1ac493b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "df1=pd.read_csv(\"/content/drive/MyDrive/DATATHON/DIM_TIENDA_TRAIN_Con_Promedio.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Imputación de datos en MTS2VENTAS_NUM con el promedio de todos los datos"
      ],
      "metadata": {
        "id": "QnRWQwlZ6Ja0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "promedio=np.mean(df1['MTS2VENTAS_NUM'])\n",
        "print(promedio)\n",
        "\n",
        "for valor in df1['MTS2VENTAS_NUM']:\n",
        "  if valor==0:\n",
        "    df1['MTS2VENTAS_NUM'].replace(0, promedio, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pivhIJNNbDWB",
        "outputId": "ab6fa56e-b4b2-43cb-d20f-e40761ef8977"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78.8974553101998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-51e78530e3a8>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df1['MTS2VENTAS_NUM'].replace(0, promedio, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Eliminación de variable CAJONESESTACIONAMIENTO_NUM, debido a que no se sabe si son valores NaN o si en realidad la sucursal tiene 0 cajones de estacionamiento se elimina ya que los ceros conforman 50% de los datos dentro de esta variable"
      ],
      "metadata": {
        "id": "r2qdZ3YV6Oss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df1.drop('CAJONESESTACIONAMIENTO_NUM', axis=1)"
      ],
      "metadata": {
        "id": "zdoN45kkSjb9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Imputación de datos en PUERTASREFRIG_NUM con el promedio redondeado"
      ],
      "metadata": {
        "id": "sqdQ1ghZ6aZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean1=np.mean(df1['PUERTASREFRIG_NUM'])\n",
        "print(mean1)\n",
        "mean_refrigeradores=round(mean1)\n",
        "print(mean_refrigeradores)\n",
        "\n",
        "for valor in df1['PUERTASREFRIG_NUM']:\n",
        "  if valor==0:\n",
        "    df1['PUERTASREFRIG_NUM'].replace(0, mean_refrigeradores, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg4emdQwT2eP",
        "outputId": "2e89b935-6d96-4a24-d893-7cf9efe2d80b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.468980021030495\n",
            "9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-d0b5a5dd4059>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df1['PUERTASREFRIG_NUM'].replace(0, mean_refrigeradores, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Imputación de valores NaN en la variable SEGMENTO_MAESTRO_DESC con la moda para cada ENTORNO_DES"
      ],
      "metadata": {
        "id": "IcRaRfna6hQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['SEGMENTO_MAESTRO_DESC'].replace(['Base', 'Hogar', 'Receso'], 'Hogar Reunion', inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgcSZSvOU-Th",
        "outputId": "95287ded-f0e1-44c8-f95a-a508d88a5dc7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-5a98162e3868>:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df1['SEGMENTO_MAESTRO_DESC'].replace(['Base', 'Hogar', 'Receso'], 'Hogar Reunion', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Eliminación de variable DATASET porque solo es identificación de TRAIN y TEST"
      ],
      "metadata": {
        "id": "m9yd8ZiW6yFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df1.drop('DATASET', axis=1)"
      ],
      "metadata": {
        "id": "RY-b9fdCX6m3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Descarga de archivo csv"
      ],
      "metadata": {
        "id": "h8r6lGsd66m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv('DIM_TIENDA_TRAIN_IMPUTADO2.csv', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "2XEkuwewYDBb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv('/content/drive/MyDrive/DATATHON/DIM_TIENDA_TRAIN_IMPUTADO2.csv', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "FZrTL_-eYlbN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Agrupación por clustering dependiendo de las coordenadas para mantener las ubicaciones como variables categóricas.\n",
        "\n",
        "Se juntan datos TRAIN y TEST para que haga los mismos clusterings y después se vuelven a separar"
      ],
      "metadata": {
        "id": "SvkBQ0Uz6-yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "data_train = pd.read_csv(\"/content/drive/MyDrive/DATATHON/DIM_TIENDA_TRAIN_IMPUTADO2.csv\")\n",
        "data_test = pd.read_csv(\"/content/drive/MyDrive/DATATHON/DIM_TIENDA_TEST_Con_Promedio.csv\")\n",
        "\n",
        "data_test=data_test.drop(['CAJONESESTACIONAMIENTO_NUM', 'DATASET'], axis=1)\n",
        "\n",
        "#Combinamos Train y Test para que los clusters se mantengan iguales para ambos\n",
        "data_combined = pd.concat([data_train, data_test], ignore_index=True)\n",
        "\n",
        "coords_combined = data_combined[['LATITUD_NUM', 'LONGITUD_NUM']]\n",
        "\n",
        "#K-means\n",
        "k = 6  #Número de clusters\n",
        "kmeans = KMeans(n_clusters=k, random_state=42).fit(coords_combined)\n",
        "\n",
        "#Agregamos clusters como variable\n",
        "data_combined['cluster'] = kmeans.labels_\n",
        "\n",
        "#Separación train y test\n",
        "data_train_with_clusters = data_combined.iloc[:len(data_train)].copy()\n",
        "data_test_with_clusters = data_combined.iloc[len(data_train):].copy()\n",
        "\n",
        "#Eliminamos latitud y longitud\n",
        "data_train_with_clusters.to_csv(\"DIM_tienda_train_with_clusters_cleaned.csv\", index=False)\n",
        "data_test_with_clusters.to_csv(\"DIM_tienda_test_with_clusters_cleaned.csv\", index=False)\n",
        "print(\"Archivos exportados como 'DIM_tienda_train_with_clusters_cleaned.csv' y 'DIM_tienda_test_with_clusters_cleaned.csv'.\")\n",
        "\n",
        "colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred']\n",
        "\n",
        "## MAPA TRAIN ##\n",
        "map_center_train = [\n",
        "    data_train_with_clusters['LATITUD_NUM'].mean(),\n",
        "    data_train_with_clusters['LONGITUD_NUM'].mean()\n",
        "]\n",
        "map_train = folium.Map(location=map_center_train, zoom_start=10)\n",
        "\n",
        "for _, row in data_train_with_clusters.iterrows():\n",
        "    color_index = row['cluster'] % len(colors)\n",
        "    folium.CircleMarker(\n",
        "        location=[row['LATITUD_NUM'], row['LONGITUD_NUM']],\n",
        "        radius=5,\n",
        "        color=colors[color_index],\n",
        "        fill=True,\n",
        "        fill_color=colors[color_index],\n",
        "        fill_opacity=0.7,\n",
        "        popup=f\"Cluster: {row['cluster']}<br>Lat: {row['LATITUD_NUM']}<br>Lon: {row['LONGITUD_NUM']}\"\n",
        "    ).add_to(map_train)\n",
        "\n",
        "map_train.save(\"clusters_train_map.html\")\n",
        "print(\"Mapa del conjunto TRAIN guardado como 'clusters_train_map.html'.\")\n",
        "\n",
        "## MAPA TEST ##\n",
        "map_center_test = [\n",
        "    data_test_with_clusters['LATITUD_NUM'].mean(),\n",
        "    data_test_with_clusters['LONGITUD_NUM'].mean()\n",
        "]\n",
        "map_test = folium.Map(location=map_center_test, zoom_start=10)\n",
        "\n",
        "for _, row in data_test_with_clusters.iterrows():\n",
        "    color_index = row['cluster'] % len(colors)\n",
        "    folium.CircleMarker(\n",
        "        location=[row['LATITUD_NUM'], row['LONGITUD_NUM']],\n",
        "        radius=5,\n",
        "        color=colors[color_index],\n",
        "        fill=True,\n",
        "        fill_color=colors[color_index],\n",
        "        fill_opacity=0.7,\n",
        "        popup=f\"Cluster: {row['cluster']}<br>Lat: {row['LATITUD_NUM']}<br>Lon: {row['LONGITUD_NUM']}\"\n",
        "    ).add_to(map_test)\n",
        "\n",
        "map_test.save(\"clusters_test_map.html\")\n",
        "print(\"Mapa del conjunto TEST guardado como 'clusters_test_map.html'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2cafsRb_aGt",
        "outputId": "2f48a437-249c-4ae0-9e3c-dfb35fe60c70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos exportados como 'DIM_tienda_train_with_clusters_cleaned.csv' y 'DIM_tienda_test_with_clusters_cleaned.csv'.\n",
            "Mapa del conjunto TRAIN guardado como 'clusters_train_map.html'.\n",
            "Mapa del conjunto TEST guardado como 'clusters_test_map.html'.\n"
          ]
        }
      ]
    }
  ]
}